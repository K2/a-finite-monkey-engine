"""
LlamaIndex documentor agent implementation

This module provides integration with LlamaIndex's agent framework for
report generation based on security findings.
"""

import asyncio
from typing import List, Dict, Any, Optional, Callable, Union
import datetime

from llama_index.core.agent.workflow import FunctionAgent
from llama_index.core.tools import FunctionTool
from llama_index.llms.ollama import Ollama as LlamaOllama

from ..adapters.ollama import AsyncOllamaClient
from ..nodes_config import nodes_config


class DocumentorAgent:
    """
    Documentor agent for generating reports using LlamaIndex
    
    This agent is responsible for creating comprehensive security reports
    based on the findings from the research and validation phases.
    
    This is part of the inner agent layer in the Finite Monkey architecture,
    which uses llama-index agents for structured tasks.
    """
    
    def __init__(
        self,
        model: Optional[str] = None,
        timeout: int = 399,
        prompt_template: Optional[str] = None,
    ):
        """
        Initialize the documentor agent
        
        Args:
            model: LLM model to use
            timeout: Request timeout in seconds
            prompt_template: Custom system prompt template
        """
        # Get settings from config
        config = nodes_config()
        
        # Set up the model
        self.model = model or config.WORKFLOW_MODEL        
        self.timeout = timeout
        
        # Define system prompt
        self.system_prompt = prompt_template or (
            "You are an expert smart contract security report writer. Your task is to synthesize "
            "security findings into comprehensive, well-structured reports that clearly communicate "
            "vulnerabilities, their impact, and recommended fixes. Your reports should be accessible "
            "to both technical and non-technical stakeholders."
        )
        
        # Initialize the LlamaIndex agent
        self._setup_agent()
    
    def _setup_agent(self):
        """Set up the LlamaIndex agent with appropriate tools"""
        
        # Define reporting tools
        def format_findings_section(
            findings: List[Dict[str, Any]],
            validation_results: Dict[str, Any]
        ) -> str:
            """
            Format the findings section of a security report.
            
            Args:
                findings: List of security findings
                validation_results: Validation results for those findings
                
            Returns:
                Formatted findings section
            """
            # This is a stub - the actual formatting is done by the LLM
            # We just define the tool interface here and the LLM will
            # decide what to return based on its analysis
            return ""
        
        def generate_executive_summary(
            project_name: str,
            findings: List[Dict[str, Any]],
            validation_results: Dict[str, Any]
        ) -> str:
            """
            Generate an executive summary for a security report.
            
            Args:
                project_name: Name of the project
                findings: List of security findings
                validation_results: Validation results for those findings
                
            Returns:
                Executive summary
            """
            # This is a stub - the actual summary is generated by the LLM
            # We just define the tool interface here and the LLM will
            # decide what to return based on its analysis
            return ""
        
        # Create tools
        tools = [
            FunctionTool.from_defaults(fn=format_findings_section),
            FunctionTool.from_defaults(fn=generate_executive_summary),
        ]
        
        # Create LlamaIndex agent
        self.agent = FunctionAgent(
            name="SecurityReportWriter",
            description="Generates comprehensive security audit reports",
            tools=tools,
            llm=LlamaOllama(model=self.model, request_timeout=self.timeout),
            system_prompt=self.system_prompt,
        )
    
    async def generate_report(
        self,
        code: str,
        project_name: str,
        findings: List[Dict[str, Any]],
        validation_results: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a security report using the documentor agent
        
        Args:
            code: Solidity code being analyzed
            project_name: Name of the project
            findings: List of findings from the research phase
            validation_results: Results from the validation phase
            
        Returns:
            Generated report
        """
        # Format findings and validation for the prompt
        findings_str = ""
        for i, finding in enumerate(findings, 1):
            finding_type = finding.get("type", "Unknown")
            severity = finding.get("severity", "Medium")
            description = finding.get("description", "No description provided")
            location = finding.get("location", "Unknown location")
            
            findings_str += f"Finding #{i}: {finding_type} (Severity: {severity})\n"
            findings_str += f"Location: {location}\n"
            findings_str += f"Description: {description}\n\n"
        
        # Format validation results
        validation_str = ""
        confirmed = validation_results.get("confirmed", [])
        false_positives = validation_results.get("false_positives", [])
        missed = validation_results.get("missed_vulnerabilities", [])
        
        validation_str += f"Confirmed Findings: {len(confirmed)}\n"
        validation_str += f"False Positives: {len(false_positives)}\n"
        validation_str += f"Missed Vulnerabilities: {len(missed)}\n\n"
        
        # Add details of missed vulnerabilities
        if missed:
            validation_str += "Missed Vulnerabilities:\n"
            for i, vuln in enumerate(missed, 1):
                validation_str += f"{i}. {vuln.get('description', 'No description')}\n"
        
        # Prepare the prompt
        prompt = f"""
        Generate a comprehensive security audit report for the '{project_name}' project.
        
        CODE BEING AUDITED:
        ```solidity
        {code}
        ```
        
        FINDINGS:
        {findings_str}
        
        VALIDATION RESULTS:
        {validation_str}
        
        Your report should include:
        1. An executive summary
        2. Detailed explanation of each vulnerability
        3. Severity assessment for each issue
        4. Impact analysis
        5. Concrete remediation recommendations
        6. General security recommendations
        
        Format the report in Markdown with clear headings, code blocks, and formatting.
        The report should be comprehensive, professional, and suitable for technical and business stakeholders.
        """
        
        # Run the agent (use run() instead of arun() for compatibility)
        response = await self.agent.run(prompt)
        
        # Process response
        report_text = str(response)
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Add metadata
        report_text = f"# Smart Contract Audit Report: {project_name}\n\n*Generated on: {current_time}*\n\n{report_text}"
        
        return {
            "markdown": report_text,
            "project_name": project_name,
            "timestamp": current_time,
            "num_findings": len(findings),
            "num_confirmed": len(confirmed),
            "num_false_positives": len(false_positives),
            "num_missed": len(missed),
        }