"""
Smart contract vulnerability scanner that adapts based on identified business flows.
"""
import asyncio
import json
from typing import Dict, List, Any, Optional, Set
from loguru import logger
from datetime import datetime
from ..pipeline.core import Context
from ..utils.llm_interface import call_llm, extract_text_from_response
from ..nodes_config import config  # Import the central configuration

class VulnerabilityScanner:
    """Scans smart contracts for security vulnerabilities with flow-aware contextual analysis."""
    
    def __init__(self, llm_adapter=None):
        """
        Initialize the vulnerability scanner.
        
        Args:
            llm_adapter: Optional LLM adapter for scanning
        """
        self.llm_adapter = llm_adapter
        # Get specific vulnerability scanning parameters from config
        self.request_timeout = getattr(config, "REQUEST_TIMEOUT", 900.0)
        self.max_concurrent_scans = getattr(config, "MAX_CONCURRENT_SCANS", 3)
        self.scan_throttle = getattr(config, "SCAN_THROTTLE", 0.5)  # seconds between scans
        
        # Create a semaphore to limit concurrent scans
        self._scan_semaphore = asyncio.Semaphore(self.max_concurrent_scans)
        
        # Vulnerability categories to scan for
        self.vuln_categories = getattr(config, "VULNERABILITY_CATEGORIES", [
            "reentrancy", "access_control", "arithmetic", "front_running",
            "unchecked_return", "denial_of_service", "time_manipulation",
            "gas_issues", "logic_errors", "backdoors"
        ])
        
        logger.info(f"Initialized vulnerability scanner with {len(self.vuln_categories)} categories")
        
    async def process(self, context: Context) -> Context:
        """
        Process the context to find vulnerabilities in smart contracts.
        
        Args:
            context: The context containing the contracts to scan
            
        Returns:
            Updated context with vulnerability information
        """
        logger.info("Starting vulnerability scanning")
        
        # Initialize vulnerabilities dict in context if not present
        if not hasattr(context, 'vulnerabilities'):
            context.vulnerabilities = {}
        
        # Check if contracts are available
        if not hasattr(context, 'contracts') or not context.contracts:
            logger.warning("No contracts found for vulnerability scanning")
            return context
        
        # Initialize vector store for vulnerability patterns if needed
        await self._initialize_vector_store(context)
                
        # Gather all relevant analysis from previous stages
        integrated_context = self._build_integrated_context(context)
        
        # Process contracts in parallel with semaphore for limiting concurrency
        tasks = []
        for contract in context.contracts:
            # Pass context to the scan method
            task = asyncio.create_task(self._scan_file_with_throttle(contract, integrated_context, context))
            tasks.append(task)
                
        # Wait for all tasks to complete
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        error_count = 0
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_count += 1
                logger.error(f"Error in scan task {i}: {result}")
        
        if error_count:
            logger.warning(f"{error_count} out of {len(tasks)} scan tasks failed")
        
        # Update vector store with newly found vulnerabilities
        await self._update_vector_store(context)
                    
        logger.info(f"Vulnerability scanning complete. Found vulnerabilities in {len(context.vulnerabilities)} contracts")
        return context
    
    async def _initialize_vector_store(self, context: Context) -> None:
        """
        Initialize the vector store for vulnerability patterns.
        
        Args:
            context: The pipeline context
        """
        try:
            # Check if vector store is available in the context
            if not hasattr(context, 'vector_store'):
                logger.info("Initializing vector store for vulnerability patterns")
                
                # Import the vector store implementation
                from ..llama_index.vector_store import VectorStore
                
                # Create a new vector store instance if needed
                # Use the storage directory from config
                storage_dir = getattr(config, "VECTOR_STORE_DIR", "./vector_store")
                
                # Initialize the vector store with vulnerability collection
                context.vector_store = VectorStore(
                    storage_dir=storage_dir,
                    collection_name="vulnerabilities"
                )
                
                logger.info(f"Vector store initialized at {storage_dir}")
            else:
                logger.debug("Vector store already initialized")
                
        except ImportError:
            logger.warning("Vector store module not available, skipping vector-based enhancement")
        except Exception as e:
            logger.error(f"Error initializing vector store: {e}")

    async def _update_vector_store(self, context: Context) -> None:
        """
        Update the vector store with newly found vulnerabilities.
        
        Args:
            context: The pipeline context with vulnerability information
        """
        if not hasattr(context, 'vector_store') or not hasattr(context, 'vulnerabilities'):
            return
            
        try:
            logger.info("Updating vector store with new vulnerabilities")
            
            # Prepare vulnerability documents for indexing
            documents = []
            
            for contract_name, vulns in context.vulnerabilities.items():
                for vuln in vulns:
                    # Create a document for each vulnerability
                    doc_text = f"""
                    Contract: {contract_name}
                    Vulnerability: {vuln.get('name', 'Unknown')}
                    Severity: {vuln.get('severity', 'Unknown')}
                    Description: {vuln.get('description', '')}
                    Location: {vuln.get('location', '')}
                    Code: {vuln.get('code_snippet', '')}
                    """
                    
                    # Create metadata for the vulnerability
                    metadata = {
                        'contract_name': contract_name,
                        'vuln_name': vuln.get('name', 'Unknown'),
                        'severity': vuln.get('severity', 'Unknown'),
                        'location': vuln.get('location', ''),
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    # Add to documents list
                    documents.append({'text': doc_text, 'metadata': metadata})
            
            # Add documents to vector store if we have any
            if documents:
                await context.vector_store.add_documents(documents)
                logger.info(f"Added {len(documents)} vulnerability documents to vector store")
            
        except Exception as e:
            logger.error(f"Error updating vector store: {e}")

    async def _find_similar_vulnerabilities(
        self, 
        content: str, 
        contract_context: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        Query the vector store to find similar vulnerability patterns.
        
        Args:
            content: The contract content to analyze
            contract_context: Context from previous analysis stages
            
        Returns:
            List of similar vulnerabilities
        """
        similar_vulns = []
        
        try:
            # Check if we have access to the vector store
            if not hasattr(self, 'context') or not hasattr(self.context, 'vector_store'):
                return similar_vulns
                
            # Extract key sections from the contract to use as queries
            queries = self._extract_query_sections(content, contract_context)
            
            # Query the vector store with each section
            for query in queries:
                results = await self.context.vector_store.query(
                    text=query,
                    top_k=3,  # Get top 3 matches
                    collection_name="vulnerabilities"
                )
                
                if results:
                    similar_vulns.extend(results)
                    
            # Deduplicate results
            seen = set()
            unique_vulns = []
            
            for vuln in similar_vulns:
                vuln_id = f"{vuln.get('metadata', {}).get('contract_name')}:{vuln.get('metadata', {}).get('vuln_name')}"
                if vuln_id not in seen:
                    seen.add(vuln_id)
                    unique_vulns.append(vuln)
                    
            return unique_vulns[:5]  # Limit to top 5 unique vulnerabilities
            
        except Exception as e:
            logger.warning(f"Error querying vector store for similar vulnerabilities: {e}")
            return similar_vulns

    def _extract_query_sections(self, content: str, contract_context: Dict[str, Any] = None) -> List[str]:
        """
        Extract sections from the contract to use as queries.
        
        Args:
            content: The contract content
            contract_context: Context from previous analysis stages
            
        Returns:
            List of query sections
        """
        queries = []
        
        # Start with the whole contract as a query
        queries.append(content[:1000])  # Use first 1000 chars for overall context
        
        # Extract function bodies if applicable
        import re
        function_pattern = r'function\s+(\w+)\s*\([^)]*\)\s*(?:public|private|internal|external)?\s*(?:view|pure)?\s*(?:returns\s*\([^)]*\))?\s*\{([^}]*)\}'
        
        functions = re.finditer(function_pattern, content)
        for match in functions:
            func_name = match.group(1)
            func_body = match.group(2)
            
            # If we have context about key functions, prioritize those
            if contract_context and 'flows' in contract_context and func_name in contract_context.get('flows', {}).get('functions', []):
                queries.append(f"function {func_name} {{\n{func_body}\n}}")
        
        return queries

    def _create_system_prompt(
        self, 
        contract_context: Dict[str, Any] = None, 
        similar_vulns: List[Dict[str, Any]] = None
    ) -> str:
        """
        Create a system prompt for vulnerability scanning with integrated context.
        
        Args:
            contract_context: Context from previous analysis stages
            similar_vulns: Similar vulnerabilities from vector store
            
        Returns:
            System prompt for the LLM
        """
        # Base system prompt
        system_prompt = (
            "You are an expert smart contract security auditor. "
            "Analyze the provided Solidity code to identify security vulnerabilities "
            "and potential exploits. Focus on concrete, actionable findings with "
            "clear explanations of the risk and potential impact."
        )
        
        # Add similar vulnerability context if available
        if similar_vulns and len(similar_vulns) > 0:
            system_prompt += (
                "\n\nSimilar vulnerabilities have been found in other contracts: "
                "- Use these as reference points to identify similar issues "
                "- Don't assume these vulnerabilities exist in the current contract "
                "- Critically evaluate whether similar patterns are present"
            )
        
        # Add formatting instructions
        system_prompt += (
            "\n\nProvide your findings in a structured JSON format with these fields: "
            "'name', 'severity' (Critical, High, Medium, Low), 'description', "
            "'location', 'code_snippet', 'impact', and 'recommendation'."
        )
        
        return system_prompt

    def _create_user_prompt(
        self, 
        file_path: str, 
        content: str, 
        contract_context: Dict[str, Any] = None,
        similar_vulns: List[Dict[str, Any]] = None
    ) -> str:
        """
        Create a user prompt for vulnerability scanning with integrated context.
        
        Args:
            file_path: Path to the file
            content: Content of the file
            contract_context: Context from previous analysis stages
            similar_vulns: Similar vulnerabilities from vector store
            
        Returns:
            User prompt for the LLM
        """
        # Start with basic information about the file
        user_prompt = f"Analyze the following Solidity contract from file {file_path} for security vulnerabilities:"
        
        # Add similar vulnerability context if available
        if similar_vulns and len(similar_vulns) > 0:
            user_prompt += "\n\nSimilar vulnerabilities found in other contracts:"
            for i, vuln in enumerate(similar_vulns[:3]):  # Limit to top 3
                metadata = vuln.get('metadata', {})
                user_prompt += f"\n{i+1}. {metadata.get('vuln_name', 'Unknown vulnerability')} in {metadata.get('contract_name', 'Unknown contract')}"
                user_prompt += f"\n   Severity: {metadata.get('severity', 'Unknown')}"
                user_prompt += f"\n   Pattern: {vuln.get('text', '')[:100]}..." if 'text' in vuln else ""
        
        # Add categories to focus on
        user_prompt += "\n\nAnalyze specifically for these vulnerability categories:"
        for category in self.vuln_categories:
            user_prompt += f"\n- {category.replace('_', ' ').title()}"
        
        # Add the code to analyze
        user_prompt += f"\n\n```solidity\n{content}\n```"
        
        # Add formatting instructions
        user_prompt += """
Please provide your findings as a JSON object with the following structure:
{
  "vulnerabilities": [
    {
      "name": "Vulnerability name",
      "severity": "High/Medium/Low",
      "description": "Detailed description of the issue",
      "location": "Function or line number",
      "code_snippet": "Relevant code snippet",
      "impact": "Potential impact of the vulnerability",
      "recommendation": "How to fix the issue"
    }
  ]
}
"""
        return user_prompt

    def _build_integrated_context(self, context: Context) -> Dict[str, Any]:
        """
        Build an integrated context from all available analysis results.
        
        Args:
            context: The pipeline context with accumulated analysis
            
        Returns:
            Integrated context dictionary for vulnerability scanning
        """
        integrated_context = {}
        
        # Extract business flow information
        if hasattr(context, 'business_flows') and context.business_flows:
            logger.info("Integrating business flows into vulnerability analysis")
            integrated_context['business_flows'] = self._extract_flow_context(context)
        
        # Extract documentation quality information
        if hasattr(context, 'documentation_quality') and context.documentation_quality:
            logger.info("Integrating documentation quality into vulnerability analysis")
            doc_context = {}
            for contract_name, quality_info in context.documentation_quality.items():
                doc_context[contract_name] = {
                    'quality_score': quality_info.get('quality_score', 0) if isinstance(quality_info, dict) else 0,
                    'issues': quality_info.get('issues', []) if isinstance(quality_info, dict) else [],
                    'low_documentation': quality_info.get('quality_score', 5) < 5 if isinstance(quality_info, dict) else True
                }
            integrated_context['documentation'] = doc_context
        
        # Extract cognitive bias information
        if hasattr(context, 'cognitive_biases') and context.cognitive_biases:
            logger.info("Integrating cognitive bias analysis into vulnerability analysis")
            integrated_context['cognitive_biases'] = context.cognitive_biases
        
        # Extract dataflow information if available
        if hasattr(context, 'dataflows') and context.dataflows:
            logger.info("Integrating dataflow analysis into vulnerability analysis")
            integrated_context['dataflows'] = context.dataflows
        
        return integrated_context

    def _extract_flow_context(self, context: Context) -> Dict[str, Any]:
        """
        Extract business flow information to inform vulnerability scanning.
        
        Args:
            context: The context with business flows
            
        Returns:
            Dictionary of flow context by contract
        """
        flow_context = {}
        
        # Check if business flows exist
        if not hasattr(context, 'business_flows') or not context.business_flows:
            logger.debug("No business flows available for informing vulnerability scanning")
            return flow_context
            
        # Extract relevant information from business flows
        for contract_name, flows in context.business_flows.items():
            if not flows:
                continue
                
            # Extract flow information
            flow_info = []
            flow_types = set()
            function_names = set()
            
            for flow in flows:
                # Handle both dict and object formats
                if isinstance(flow, dict):
                    flow_info.append({
                        'name': flow.get('name', 'Unknown flow'),
                        'type': flow.get('flow_type', 'Unknown'),
                        'functions': flow.get('functions', [])
                    })
                    flow_types.add(flow.get('flow_type', 'Unknown'))
                    function_names.update(flow.get('functions', []))
                else:
                    flow_info.append({
                        'name': getattr(flow, 'name', 'Unknown flow'),
                        'type': getattr(flow, 'flow_type', 'Unknown'),
                        'functions': getattr(flow, 'functions', [])
                    })
                    flow_types.add(getattr(flow, 'flow_type', 'Unknown'))
                    function_names.update(getattr(flow, 'functions', []))
            
            flow_context[contract_name] = {
                'flows': flow_info,
                'flow_types': list(flow_types),
                'functions': list(function_names)
            }
            
        return flow_context
